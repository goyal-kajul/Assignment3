{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='C:\\\\Users\\\\KAJUL\\\\Desktop\\\\Assignment3\\\\trainX.pickle'\n",
    "infile1 = open(filename,'rb')\n",
    "trainx = pickle.load(infile1)\n",
    "filename='C:\\\\Users\\\\KAJUL\\\\Desktop\\\\Assignment3\\\\testX.pickle'\n",
    "infile2 = open(filename,'rb')\n",
    "testx = pickle.load(infile2)\n",
    "filename='C:\\\\Users\\\\KAJUL\\\\Desktop\\\\Assignment3\\\\trainY.pickle'\n",
    "infile3 = open(filename,'rb')\n",
    "trainy = pickle.load(infile3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "x_train, x_valid,y_train,y_valid=train_test_split(trainx,trainy,test_size=0.16666)\n",
    "# the data, shuffled and split between train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n",
      "(10000,)\n",
      "(10000, 28, 28)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_valid.shape)\n",
    "print(x_valid.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 28, 28)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_valid = x_valid.astype('float32')\n",
    "x_train /= 255\n",
    "x_valid /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_valid.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_valid = keras.utils.to_categorical(y_valid, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0623 16:07:53.466972 11776 deprecation_wrapper.py:119] From C:\\Users\\KAJUL\\Anaconda3\\envs\\hello-tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0623 16:07:53.534957 11776 deprecation_wrapper.py:119] From C:\\Users\\KAJUL\\Anaconda3\\envs\\hello-tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0623 16:07:53.546952 11776 deprecation_wrapper.py:119] From C:\\Users\\KAJUL\\Anaconda3\\envs\\hello-tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 16:07:53.769730 11776 deprecation_wrapper.py:119] From C:\\Users\\KAJUL\\Anaconda3\\envs\\hello-tf\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0623 16:07:53.811911 11776 deprecation_wrapper.py:119] From C:\\Users\\KAJUL\\Anaconda3\\envs\\hello-tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                3010      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 545,810\n",
      "Trainable params: 545,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x_train = np.reshape(x_train, (50000, 784))\n",
    "x_valid = np.reshape(x_valid, (10000, 784))\n",
    "print(y_valid.shape)\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=784), )\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.4))\n",
    "model.add(Dense(300))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.4))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 16:08:02.219030 11776 deprecation.py:323] From C:\\Users\\KAJUL\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0623 16:08:02.595679 11776 deprecation_wrapper.py:119] From C:\\Users\\KAJUL\\Anaconda3\\envs\\hello-tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 11s 229us/step - loss: 0.5886 - acc: 0.7868 - val_loss: 0.4334 - val_acc: 0.8443\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.4037 - acc: 0.8528 - val_loss: 0.3674 - val_acc: 0.8659\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.3540 - acc: 0.8686 - val_loss: 0.4134 - val_acc: 0.8497\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.3244 - acc: 0.8795 - val_loss: 0.3524 - val_acc: 0.8673\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.3034 - acc: 0.8875 - val_loss: 0.3217 - val_acc: 0.8820\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.2835 - acc: 0.8940 - val_loss: 0.3217 - val_acc: 0.8799\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.2715 - acc: 0.8990 - val_loss: 0.3473 - val_acc: 0.8662\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.2558 - acc: 0.9047 - val_loss: 0.3627 - val_acc: 0.8713\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.2427 - acc: 0.9080 - val_loss: 0.3219 - val_acc: 0.8825\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 0.2337 - acc: 0.9104 - val_loss: 0.3318 - val_acc: 0.8804\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 0.2235 - acc: 0.9152 - val_loss: 0.3444 - val_acc: 0.8800\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2136 - acc: 0.9187 - val_loss: 0.3173 - val_acc: 0.8895\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.2063 - acc: 0.9212 - val_loss: 0.3394 - val_acc: 0.8808\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.1970 - acc: 0.9258 - val_loss: 0.3369 - val_acc: 0.8842\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 0.1877 - acc: 0.9292 - val_loss: 0.3518 - val_acc: 0.8849\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.1818 - acc: 0.9310 - val_loss: 0.3443 - val_acc: 0.8876\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 0.1756 - acc: 0.9334 - val_loss: 0.3050 - val_acc: 0.8982\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.1675 - acc: 0.9366 - val_loss: 0.3364 - val_acc: 0.8901\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.1610 - acc: 0.9394 - val_loss: 0.3094 - val_acc: 0.8948\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.1553 - acc: 0.9410 - val_loss: 0.3400 - val_acc: 0.8852\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.1498 - acc: 0.9430 - val_loss: 0.3232 - val_acc: 0.8959\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.1436 - acc: 0.9458 - val_loss: 0.3211 - val_acc: 0.8970\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.1392 - acc: 0.9467 - val_loss: 0.3550 - val_acc: 0.8833\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.1352 - acc: 0.9491 - val_loss: 0.3281 - val_acc: 0.8966\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.1288 - acc: 0.9516 - val_loss: 0.3209 - val_acc: 0.8983\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.1248 - acc: 0.9529 - val_loss: 0.3733 - val_acc: 0.8869\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.1207 - acc: 0.9543 - val_loss: 0.3542 - val_acc: 0.8997\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.1147 - acc: 0.9566 - val_loss: 0.3855 - val_acc: 0.8911\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 0.1130 - acc: 0.9576 - val_loss: 0.3821 - val_acc: 0.8890\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.1066 - acc: 0.9601 - val_loss: 0.3660 - val_acc: 0.8956\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 0.1041 - acc: 0.9607 - val_loss: 0.4161 - val_acc: 0.8881\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.0999 - acc: 0.9624 - val_loss: 0.4034 - val_acc: 0.8987\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.0968 - acc: 0.9626 - val_loss: 0.3799 - val_acc: 0.8959\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.0933 - acc: 0.9650 - val_loss: 0.4301 - val_acc: 0.8888\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.0904 - acc: 0.9651 - val_loss: 0.4059 - val_acc: 0.8979\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.0877 - acc: 0.9669 - val_loss: 0.4039 - val_acc: 0.8895\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.0839 - acc: 0.9673 - val_loss: 0.4505 - val_acc: 0.8918\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.0821 - acc: 0.9691 - val_loss: 0.4624 - val_acc: 0.8848\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.0807 - acc: 0.9691 - val_loss: 0.4475 - val_acc: 0.8939\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.0766 - acc: 0.9712 - val_loss: 0.4263 - val_acc: 0.8989\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 0.0740 - acc: 0.9713 - val_loss: 0.4438 - val_acc: 0.8978\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.0716 - acc: 0.9732 - val_loss: 0.4446 - val_acc: 0.8985\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.0722 - acc: 0.9725 - val_loss: 0.4071 - val_acc: 0.8995\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 0.0660 - acc: 0.9756 - val_loss: 0.4541 - val_acc: 0.9023\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.0653 - acc: 0.9752 - val_loss: 0.4462 - val_acc: 0.8981\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.0618 - acc: 0.9756 - val_loss: 0.4609 - val_acc: 0.8967\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.0617 - acc: 0.9770 - val_loss: 0.4265 - val_acc: 0.9039\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.0595 - acc: 0.9770 - val_loss: 0.4546 - val_acc: 0.9031\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.0587 - acc: 0.9782 - val_loss: 0.4615 - val_acc: 0.8960\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.0561 - acc: 0.9788 - val_loss: 0.4960 - val_acc: 0.8934\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.0521 - acc: 0.9808 - val_loss: 0.4928 - val_acc: 0.9023\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.0525 - acc: 0.9805 - val_loss: 0.4906 - val_acc: 0.8997\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.0492 - acc: 0.9818 - val_loss: 0.5177 - val_acc: 0.8993\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.0492 - acc: 0.9816 - val_loss: 0.5076 - val_acc: 0.8921\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 0.0469 - acc: 0.9824 - val_loss: 0.5573 - val_acc: 0.8981\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.0478 - acc: 0.9817 - val_loss: 0.5737 - val_acc: 0.8843\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.0450 - acc: 0.9835 - val_loss: 0.5667 - val_acc: 0.8931\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.0428 - acc: 0.9845 - val_loss: 0.5239 - val_acc: 0.8993\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.0440 - acc: 0.9835 - val_loss: 0.5168 - val_acc: 0.8994\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.0390 - acc: 0.9851 - val_loss: 0.5976 - val_acc: 0.8959\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.0380 - acc: 0.9863 - val_loss: 0.5622 - val_acc: 0.8982\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 0.0377 - acc: 0.9863 - val_loss: 0.5815 - val_acc: 0.8965\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.0374 - acc: 0.9863 - val_loss: 0.5816 - val_acc: 0.8905\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 0.0376 - acc: 0.9858 - val_loss: 0.6124 - val_acc: 0.8963\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 0.0361 - acc: 0.9872 - val_loss: 0.5935 - val_acc: 0.8926\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 0.0352 - acc: 0.9872 - val_loss: 0.5674 - val_acc: 0.8977\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.0328 - acc: 0.9883 - val_loss: 0.6075 - val_acc: 0.8955\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.0337 - acc: 0.9878 - val_loss: 0.6183 - val_acc: 0.8952\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.0313 - acc: 0.9888 - val_loss: 0.5473 - val_acc: 0.9000\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 0.0308 - acc: 0.9885 - val_loss: 0.5939 - val_acc: 0.9010\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.0276 - acc: 0.9897 - val_loss: 0.5727 - val_acc: 0.8998\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.0300 - acc: 0.9894 - val_loss: 0.6239 - val_acc: 0.9004\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.0299 - acc: 0.9895 - val_loss: 0.5907 - val_acc: 0.8998\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.0258 - acc: 0.9908 - val_loss: 0.5679 - val_acc: 0.9026\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.0275 - acc: 0.9901 - val_loss: 0.6041 - val_acc: 0.9024\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.0257 - acc: 0.9905 - val_loss: 0.6495 - val_acc: 0.8929\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.0263 - acc: 0.9904 - val_loss: 0.5744 - val_acc: 0.9020\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.0247 - acc: 0.9910 - val_loss: 0.6335 - val_acc: 0.8988\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.0260 - acc: 0.9908 - val_loss: 0.6016 - val_acc: 0.8980\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.0236 - acc: 0.9916 - val_loss: 0.6458 - val_acc: 0.8965\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.0227 - acc: 0.9921 - val_loss: 0.6183 - val_acc: 0.9045\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.0221 - acc: 0.9919 - val_loss: 0.6738 - val_acc: 0.9011\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.0211 - acc: 0.9929 - val_loss: 0.6071 - val_acc: 0.9010\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.0212 - acc: 0.9926 - val_loss: 0.6170 - val_acc: 0.9015\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.0210 - acc: 0.9926 - val_loss: 0.7176 - val_acc: 0.8945\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.0213 - acc: 0.9927 - val_loss: 0.6481 - val_acc: 0.9013\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.0188 - acc: 0.9934 - val_loss: 0.6193 - val_acc: 0.9000\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.0191 - acc: 0.9937 - val_loss: 0.6275 - val_acc: 0.8987\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.0206 - acc: 0.9923 - val_loss: 0.6339 - val_acc: 0.9046\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.0196 - acc: 0.9934 - val_loss: 0.6577 - val_acc: 0.9008\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.0184 - acc: 0.9932 - val_loss: 0.7106 - val_acc: 0.8947\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.0168 - acc: 0.9943 - val_loss: 0.6710 - val_acc: 0.8981\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.0165 - acc: 0.9946 - val_loss: 0.6928 - val_acc: 0.9011\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.0179 - acc: 0.9938 - val_loss: 0.7256 - val_acc: 0.8955\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.0172 - acc: 0.9940 - val_loss: 0.6793 - val_acc: 0.9017\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.0164 - acc: 0.9940 - val_loss: 0.6586 - val_acc: 0.8990\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.0176 - acc: 0.9937 - val_loss: 0.6961 - val_acc: 0.8972\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.0169 - acc: 0.9943 - val_loss: 0.6959 - val_acc: 0.8980\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.0144 - acc: 0.9955 - val_loss: 0.6868 - val_acc: 0.8986\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.0144 - acc: 0.9950 - val_loss: 0.6999 - val_acc: 0.8980\n",
      "Test loss: 0.6999144237615518\n",
      "Test accuracy: 0.898\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_valid, y_valid))\n",
    "\n",
    "score = model.evaluate(x_valid, y_valid, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testx = np.reshape(testx, (10000, 784))\n",
    "pred=model.predict(testx)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pred,open(\"testY.pickle\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29410940be0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(testx[5500],cmap='gist_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainy[5500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x294109a1d30>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(trainx[20000],cmap='gist_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
